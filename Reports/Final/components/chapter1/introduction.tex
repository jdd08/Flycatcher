\chapter{Introduction}
\pagestyle{plain}
\setcounter{page}{1}
Software testing is a cornerstone of software engineering --- one of the most common and effective ways to verify software quality and an effort that accounts for at least 50\% of software development time \cite{tahbildar2automated}. With the fast-paced growth of the software industry, comes the need to test large and complex software on an unprecedented scale. Moreover, as software becomes increasingly ubiquitous, it is held to the highest standards of reliability and correctness, which further justifies testing it in a rigorous and exhaustive manner.

As a result, many attempts have been made to automate the testing effort, so that programs can be systematically and seamlessly tested, without requiring laborious, costly and error-prone manual input. The consequences of automated testing are very appealing: it reduces software maintenance and development costs, while increasing the robustness and ultimate quality of the software. Despite the fact that this area of research has taken time to develop, due to the intrinsic complexities of automatic test generation, it has now seemingly reached a stage where it can start to make a meaningful impact on software testing practice.

% have been left on the side line  s/ out of the equation ?
Decades of research have been devoted to automatic test generation for static languages and a multitude of tools have been developed. As the research area matures, it is arriving to a point where its techniques are no longer simply applicable to restricted programming language subsets or limited programs. Indeed, companies such as Microsoft employ automatic test generation tools on a regular basis to verify their software \cite{păsăreanu2009survey}. Yet, until very recently, dynamic programming languages had been left out of the equation --- but their increasing popularity and a renewed interest in them prompts the need to start including them in the automatic testing research effort.

One such programming language that has been growing in popularity in the past few years is JavaScript, with new frameworks and libraries frequently being released for it. Software libraries that have gained wide acceptance, like \emph{Node.js}\footnote{http://nodejs.org/} which supports the writing of highly-scalable internet applications, seem to confirm JavaScript's transition from a purely client-side browser language to an all-purpose one --- at least for some. In recent studies \cite{website:langpop}, JavaScript appears amongst the most used programming languages in the world today. In other words, it seems that JavaScript is here to stay, at least for some time, and it thus makes sense to choose it as the object of our work in automatic testing for dynamic languages.

Various test generation approaches exist: from straightforward but limited random generation to elaborate systems that combine static and dynamic analysis to provide strong software verification. Since much of the literature on automatic test generation focuses on static procedural languages and numerical input data types, many of the techniques found are not feasible or applicable to automatic test generation for JavaScript and herein lies the main element of risk in this project. On top of that, automatic test generation is not without its challenges. Both the static and dynamic solutions that aim for systematic testing face major hurdles. For the static approach, it is mainly to do with solving the path constraints responsible for generating the test data, as this problem can become undecidable under certain circumstances. The dynamic approach depends on the \emph{execution} of the program under test, and the number of executions needed for sufficient coverage can become infeasible.

In this report, we present \textsf{Flycatcher}, a program written in JavaScript, that combines existing and innovative methods to achieve automatic generation of unit tests for JavaScript. The word \emph{automatic} is key here, as we believe that to be really useful such a tool requires minimal input from its user. This design choice will therefore guide our decisions throughout, as we strive to create a tool that works autonomously. On top of the challenges listed above that are common to most automatic test case generation initiatives, \textsf{Flycatcher} raises additional difficulties due to the fact that it targets not only an object-oriented\footnote{this has been debated, but JavaScript is heavily object-based and can support polymorphism, inheritance and encapsulation, which we believe is sufficient to call it an object-oriented language} language but a dynamically-typed one. For instance, our testing tool will need to tackle issues such as the generation of method call sequences and dynamically-typed instances, the latter made difficult by the absence of static types.

\subsubsection{Contribution}

The major contribution that this project makes to the field is to extend the limited amount of work done in automatic test generation for dynamic languages by proposing a tool that successfully generates unit test suites for a comprehensive subset of the JavaScript language. As well as helping JavaScript developers in their testing effort, we hope that our work will be able to offer new insights into automatic test generation for object-oriented programs in dynamic languages, and benefit future research in that direction.