\chapter{Introduction}
\pagestyle{plain}
\setcounter{page}{1}
Software testing is a cornerstone of software engineering --- one of the most common and effective ways to verify software quality and an effort that accounts for at least 50\% of software development time \cite{tahbildar2automated}. With the fast-paced growth of the software industry, comes the need to test larger and more complex software on an unprecedented scale. Moreover, as software becomes increasingly ubiquitous, it is held to the highest standards of reliability and correctness, which further justifies testing it in a rigorous and exhaustive manner.

As a result, many attempts have been made to automate the testing effort, so that programs can be systematically and seamlessly tested, without requiring laborious, costly and error-prone manual input. The consequences of automated testing are very appealing: it reduces software maintenance and development costs, while increasing the robustness and ultimate quality of the software. Despite the fact that this area of research has taken time to develop, due to the intrinsic complexities of automatic test generation, it has now seemingly reached a stage where it can start to make a meaningful impact on software testing practice.

% have been left on the side line  s/ out of the equation ?
Decades of research have been devoted to automatic test generation for static languages and a multitude of tools have been developed. As the research area matures, it is arriving to a point where its techniques are no longer simply applicable to restricted programming language subsets or limited programs. Indeed, companies such as Microsoft employ automatic test generation tools on a regular basis to verify their software \cite{păsăreanu2009survey}. Yet, until very recently, dynamic programming languages had been left out of the equation --- but their increasing popularity and a renewed interest in them prompts the need to start including them in the automatic testing research effort.

One such programming language that has been growing in popularity in the past few years is JavaScript, with new frameworks and libraries frequently being released for it. Software libraries that have gained wide acceptance, like \texttt{Node.js}\footnote{http://nodejs.org/} which supports the writing of highly-scalable internet applications, seem to confirm JavaScript's transition from a purely client-side browser language to an all-purpose one --- at least for some. In recent studies \cite{website:langpop}, JavaScript appears amongst the most used programming languages in the world today. In other words, it seems that JavaScript is here to stay, at least for some time, and it makes sense to devote time to it.

Various test generation approaches exist: from straightforward but limited random generation to elaborate systems that combine static and dynamic analysis to provide strong software verification. Since much of the literature on automatic test generation focuses on static procedural languages and numerical input data types, many of the techniques found are not feasible or applicable to automatic test generation for JavaScript. However, some are more appropriate than others for our objective --- to generate structural unit test suites for JavaScript objects --- and it is those methods that we will explore during the course of this project.\\

This project is challenging for several reasons. First of all, it requires automatic test data generation, which is a challenging task in itself. Taking a random approach to the data generation problem is often not satisfactory, as the coverage achieved tends to be fairly poor. However, both the static and dynamic solutions that aim for a more systematic testing face major hurdles. For the static approach it is mainly to do with solving the constraints responsible for generating the test data, as this problem can become undecidable under certain circumstances. The dynamic approach depends on the execution of the program under test, and the number of executions needed for sufficient coverage can become infeasible. On top of these challenges that are common to most automatic test case generation initiatives, \textsf{Flycatcher} raises additional difficulties due to the fact that it targets not only an object-oriented language but a dynamic one. For instance, our testing tool will need to tackle issues such as method call sequence generation and dynamically-typed object instance generation, the latter rendered difficult by the absence of static types.

By investigating and bringing together the most relevant techniques, we believe that we can overcome the challenges encountered. The major contribution that this project hopes to make to the field is to extend the limited amount of work done regarding dynamic languages by proposing a tool for automatic structural unit test generation for, possibly restricted, JavaScript programs. As well as offering a potential tool to aid JavaScript developers, we hope that our work will be able to offer new insights into automatic test generation for a dynamic, object-oriented language and benefit future research in that direction.